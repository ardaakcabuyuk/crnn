{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.py\n",
    "common_config = {\n",
    "    'data_dir': 'data/mnt/ramdisk/max/90kDICT32px/',\n",
    "    'img_width': 100,\n",
    "    'img_height': 32,\n",
    "    'map_to_seq_hidden': 64,\n",
    "    'rnn_hidden': 256,\n",
    "    'leaky_relu': False,\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'epochs': 10000,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 512,\n",
    "    'lr': 0.0005,\n",
    "    'show_interval': 10,\n",
    "    'valid_interval': 500,\n",
    "    'save_interval': 2000,\n",
    "    'cpu_workers': 4,\n",
    "    'reload_checkpoint': None,\n",
    "    'valid_max_iter': 100,\n",
    "    'decode_method': 'greedy',\n",
    "    'beam_size': 10,\n",
    "    'checkpoints_dir': 'checkpoints/'\n",
    "}\n",
    "train_config.update(common_config)\n",
    "\n",
    "evaluate_config = {\n",
    "    'eval_batch_size': 512,\n",
    "    'cpu_workers': 4,\n",
    "    'reload_checkpoint': 'checkpoints/crnn_synth90k.pt',\n",
    "    'decode_method': 'beam_search',\n",
    "    'beam_size': 10,\n",
    "}\n",
    "evaluate_config.update(common_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, height, width, num_class,\n",
    "                 map_to_seq_hidden=64, rnn_hidden=256, use_leaky_relu=False):\n",
    "        \n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        self.cnn, (output_channels, output_height, output_width) = \\\n",
    "            self.cnn_backbone(channels, height, width, use_leaky_relu)\n",
    "        \n",
    "        self.map_to_sequential = nn.Linear(output_channel *  output_height, map_to_seq_hidden)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(cnn_to_rnn_hidden, rnn_hidden, bidirectional=True)\n",
    "        self.rnn2 = nn.LSTM(2 * rnn_hidden, rnn_hidden, bidirectional=True)\n",
    "        \n",
    "        self.dense = nn.Linear(2 * rnn_hidden, num_class)\n",
    "    \n",
    "    def cnn_backbone(self, channels, height, width, use_leaky_relu):\n",
    "        channels = [channels, 64, 128, 256, 256, 512, 512, 512]\n",
    "        kernels = [3, 3, 3, 3, 3, 3, 2]\n",
    "        strides = [1, 1, 1, 1, 1, 1, 1]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 0]\n",
    "        \n",
    "        cnn = nn.Sequential()\n",
    "        \n",
    "        def convolution_relu(i, batch_norm=False):\n",
    "            # input shape: (batch size, input_channels, height, width)\n",
    "            input_channels = channels[i]\n",
    "            output_channels = channels[i + 1]\n",
    "            \n",
    "            cnn.add_module('conv-{}'.format(i), nn.Conv2d(input_channels, output_channels, kernels[i], strides[i], paddings[i]))\n",
    "            \n",
    "            if batch_norm:\n",
    "                cnn.add_module('batchnorm-{}'.format(i), nn.BatchNorm2d(output_channel))\n",
    "            \n",
    "            if use_leaky_relu:\n",
    "                relu = nn.LeakyReLU(0.2, inplace = True)\n",
    "            else:\n",
    "                relu = nn.ReLU(inplace = True)\n",
    "                \n",
    "            cnn.add_module('relu-{}'.format(i))\n",
    "            \n",
    "        \n",
    "        # size of image: (channels, height, width)\n",
    "        \n",
    "        convolution_relu(0)\n",
    "        cnn.add_module('maxpool-0', nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # (64, height // 2, width // 2)\n",
    "        \n",
    "        convolution_relu(1)\n",
    "        cnn.add_module('maxpool-1', nn.MaxPool2d(kernel_size = 2, stride = 2))   \n",
    "        # (128, height // 4, width // 4)\n",
    "        \n",
    "        convolution_relu(2)\n",
    "        convolution_relu(3)\n",
    "        cnn.add_module('maxpool-2', nn.MaxPool2d(kernel_size = (2,1)))\n",
    "        # (256, height // 8, width // 4)\n",
    "        \n",
    "        convolution.relu(4, batch_norm=True)\n",
    "        convolution.relu(5, batch_norm=True)\n",
    "        cnn.add_module('maxpool-3', nn.MaxPool2d(kernel_size = (2,1)))\n",
    "        # (512, height // 16, width // 4)\n",
    "        \n",
    "        convolution_relu(6)\n",
    "        # (512, height // 16 - 1, width // 4 - 1)\n",
    "        \n",
    "        output_channels, output_height, output_width = channels[-1], height // 16 - 1, width // 4 - 1\n",
    "        return cnn, (output_channels, output_height, output_width)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # shape of images: (batch_size, channels, height, width)\n",
    "        \n",
    "        convolution = self.cnn(images)\n",
    "        batch_size, channels, height, width = convolution.size()\n",
    "        \n",
    "        convolution = convolution.view(batch, channel * height, width)\n",
    "        convolution = convolution.permute(2, 0, 1) # (width, batch_size, features)\n",
    "        \n",
    "        sequential = self.map_to_sequential(convolution)\n",
    "        \n",
    "        recurrent, _ = self.rnn1(sequential)\n",
    "        recurrent, _ = self.rnn2(recurrent)\n",
    "        \n",
    "        output = self.dense(recurrent)\n",
    "        return output # shape: (sequential_length, batch_size, num_class)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "#from config import train_config as config\n",
    "#from dataset import Synth90kDataset, synth90k_collate_fn\n",
    "#from model import CRNN\n",
    "#from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-85684fa92777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-85684fa92777>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0meval_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "def train_batch(crnn, data, optimizer, criterion, device):\n",
    "    crnn.train()\n",
    "    images, labels, label_lengths = [d.to(device) for d in data]\n",
    "    \n",
    "    logits = crnn(images)\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "    \n",
    "    batch_size = images.size(0)\n",
    "    input_lenghts = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "    label_lengths = torch.flatten(label_lenghts)\n",
    "    \n",
    "    loss = criterion(log_probs, targets, input_lengths, label_lengths)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def main():\n",
    "    epochs = config['epochs']\n",
    "    train_batch_size = config['train_batch_size']\n",
    "    eval_batch_size = config['eval_batch_size']\n",
    "    lr = config['lr']\n",
    "    show_interval = config['show_interval']\n",
    "    valid_interval = config['valid_interval']\n",
    "    save_interval = config['save_interval']\n",
    "    cpu_workers = config['cpu_workers']\n",
    "    reload_checkpoint = config['reload_checkpoint']\n",
    "    valid_max_iter = config['valid_max_iter']\n",
    "\n",
    "    img_width = config['img_width']\n",
    "    img_height = config['img_height']\n",
    "    data_dir = config['data_dir']\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    train_dataset = Synth90kDataset(root_dir=data_dir, mode='train', \n",
    "                                     img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    valid_dataset = Synth90kDataset(root_dir=data_dir, mode='dev', \n",
    "                                     img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cpu_workers,\n",
    "        collate_fn=synth90k_collate_fn)\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cpu_workers,\n",
    "        collate_fn=synth90k_collate_fn)\n",
    "\n",
    "    num_class = len(Synth90kDataset.LABEL2CHAR) + 1\n",
    "    crnn = CRNN(1, img_height, img_width, num_class,\n",
    "                map_to_seq_hidden=config['map_to_seq_hidden'],\n",
    "                rnn_hidden=config['rnn_hidden'],\n",
    "                leaky_relu=config['leaky_relu'])\n",
    "    if reload_checkpoint:\n",
    "        crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "    crnn.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(crnn.parameters(), lr=lr)\n",
    "    criterion = CTCLoss(reduction='sum')\n",
    "    criterion.to(device)\n",
    "    \n",
    "    i = 1\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'epoch: {epoch}')\n",
    "        tot_train_loss = 0.\n",
    "        tot_train_count = 0\n",
    "        for train_data in train_loader:\n",
    "            loss = train_batch(crnn, train_data, optimizer, criterion, device)\n",
    "            train_size = train_data[0].size(0)\n",
    "\n",
    "            tot_train_loss += loss\n",
    "            tot_train_count += train_size\n",
    "            if i % show_interval == 0:\n",
    "                print('train_batch_loss[', i, ']: ', loss / train_size)\n",
    "\n",
    "            if i % valid_interval == 0:\n",
    "                evaluation = evaluate(crnn, valid_loader, criterion,\n",
    "                                      decode_method=config['decode_method'],\n",
    "                                      beam_size=config['beam_size'])\n",
    "                print('valid_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n",
    "\n",
    "                if i % save_interval == 0:\n",
    "                    prefix = 'crnn'\n",
    "                    loss = evaluation['loss']\n",
    "                    save_model_path = os.path.join(config['checkpoints_dir'],\n",
    "                                                   f'{prefix}_{i:06}_loss{loss}.pt')\n",
    "                    torch.save(crnn.state_dict(), save_model_path)\n",
    "                    print('save model at ', save_model_path)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        print('train_loss: ', tot_train_loss / tot_train_count)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
