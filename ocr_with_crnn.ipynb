{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.py\n",
    "common_config = {\n",
    "    'data_dir': 'E:/indirilenler/mjsynth/mnt/ramdisk/max/90kDICT32px/',\n",
    "    'img_width': 100,\n",
    "    'img_height': 32,\n",
    "    'map_to_seq_hidden': 64,\n",
    "    'rnn_hidden': 256,\n",
    "    'use_leaky_relu': False,\n",
    "}\n",
    "\n",
    "train_config = {\n",
    "    'epochs': 1000,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_batch_size': 512,\n",
    "    'lr': 0.001,\n",
    "    'show_interval': 10,\n",
    "    'valid_interval': 10,\n",
    "    'save_interval': 2000,\n",
    "    'cpu_workers': 4,\n",
    "    'reload_checkpoint': None,\n",
    "    'valid_max_iter': 100,\n",
    "    'decode_method': 'greedy',\n",
    "    'beam_size': 10,\n",
    "    'checkpoints_dir': 'checkpoints/'\n",
    "}\n",
    "train_config.update(common_config)\n",
    "\n",
    "eval_config = {\n",
    "    'eval_batch_size': 512,\n",
    "    'cpu_workers': 4,\n",
    "    'reload_checkpoint': 'checkpoints/crnn_ocr.pt',\n",
    "    'decode_method': 'beam_search',\n",
    "    'beam_size': 10,\n",
    "}\n",
    "eval_config.update(common_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, channels, height, width, num_class,\n",
    "                 map_to_seq_hidden=64, rnn_hidden=256, use_leaky_relu=False):\n",
    "        \n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        self.cnn, (output_channels, output_height, output_width) = \\\n",
    "            self.cnn_backbone(channels, height, width, use_leaky_relu)\n",
    "        \n",
    "        self.map_to_sequential = nn.Linear(output_channels *  output_height, map_to_seq_hidden)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(map_to_seq_hidden, rnn_hidden, bidirectional=True)\n",
    "        self.rnn2 = nn.LSTM(2 * rnn_hidden, rnn_hidden, bidirectional=True)\n",
    "        \n",
    "        self.dense = nn.Linear(2 * rnn_hidden, num_class)\n",
    "    \n",
    "    def cnn_backbone(self, channels, height, width, use_leaky_relu):\n",
    "        channels = [channels, 64, 128, 256, 256, 512, 512, 512]\n",
    "        kernels = [3, 3, 3, 3, 3, 3, 2]\n",
    "        strides = [1, 1, 1, 1, 1, 1, 1]\n",
    "        paddings = [1, 1, 1, 1, 1, 1, 0]\n",
    "        \n",
    "        cnn = nn.Sequential()\n",
    "        \n",
    "        def convolution_relu(i, batch_norm=False):\n",
    "            # input shape: (batch size, input_channels, height, width)\n",
    "            input_channels = channels[i]\n",
    "            output_channels = channels[i + 1]\n",
    "            \n",
    "            cnn.add_module('conv-{}'.format(i), nn.Conv2d(input_channels, output_channels, kernels[i], strides[i], paddings[i]))\n",
    "            \n",
    "            if batch_norm:\n",
    "                cnn.add_module('batchnorm-{}'.format(i), nn.BatchNorm2d(output_channels))\n",
    "            \n",
    "            if use_leaky_relu:\n",
    "                relu = nn.LeakyReLU(0.2, inplace = True)\n",
    "            else:\n",
    "                relu = nn.ReLU(inplace = True)\n",
    "                \n",
    "            cnn.add_module('relu-{}'.format(i), relu)\n",
    "            \n",
    "        \n",
    "        # size of image: (channels, height, width)\n",
    "        \n",
    "        convolution_relu(0)\n",
    "        cnn.add_module('maxpool-0', nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # (64, height // 2, width // 2)\n",
    "        \n",
    "        convolution_relu(1)\n",
    "        cnn.add_module('maxpool-1', nn.MaxPool2d(kernel_size = 2, stride = 2))   \n",
    "        # (128, height // 4, width // 4)\n",
    "        \n",
    "        convolution_relu(2)\n",
    "        convolution_relu(3)\n",
    "        cnn.add_module('maxpool-2', nn.MaxPool2d(kernel_size = (2,1)))\n",
    "        # (256, height // 8, width // 4)\n",
    "        \n",
    "        convolution_relu(4, batch_norm=True)\n",
    "        convolution_relu(5, batch_norm=True)\n",
    "        cnn.add_module('maxpool-3', nn.MaxPool2d(kernel_size = (2,1)))\n",
    "        # (512, height // 16, width // 4)\n",
    "        \n",
    "        convolution_relu(6)\n",
    "        # (512, height // 16 - 1, width // 4 - 1)\n",
    "        \n",
    "        output_channels, output_height, output_width = channels[-1], height // 16 - 1, width // 4 - 1\n",
    "        return cnn, (output_channels, output_height, output_width)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # shape of images: (batch_size, channels, height, width)\n",
    "        \n",
    "        convolution = self.cnn(images)\n",
    "        batch_size, channels, height, width = convolution.size()\n",
    "        \n",
    "        convolution = convolution.view(batch_size, channels * height, width)\n",
    "        convolution = convolution.permute(2, 0, 1) # (width, batch_size, features)\n",
    "        \n",
    "        sequential = self.map_to_sequential(convolution)\n",
    "        \n",
    "        recurrent, _ = self.rnn1(sequential)\n",
    "        recurrent, _ = self.rnn2(recurrent)\n",
    "        \n",
    "        output = self.dense(recurrent)\n",
    "        return output # shape: (sequential_length, batch_size, num_class)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class OCR_Dataset(Dataset):\n",
    "    CHARS = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    CHAR2LABEL = {char: i + 1 for i, char in enumerate(CHARS)}\n",
    "    LABEL2CHAR = {label: char for char, label in CHAR2LABEL.items()}\n",
    "    \n",
    "    def __init__ (self, mode = None, root_dir = None, img_height = 100, img_width = 100):\n",
    "        \n",
    "        mapping = {}\n",
    "        \n",
    "        with open(os.path.join(root_dir, 'lexicon.txt'), 'r') as fr:\n",
    "            for i, line in enumerate(tqdm(fr.readlines())):\n",
    "                mapping[i] = line.strip()\n",
    "        \n",
    "        if mode == 'train':\n",
    "            path = 'annotation_train.txt'\n",
    "        elif mode == 'val':\n",
    "            path = 'annotation_val.txt'\n",
    "        elif mode == 'test':\n",
    "            path = 'annotation_test.txt'\n",
    "        else:\n",
    "            raise Exception(\"Incorrect argument for variable mode!\")\n",
    "        \n",
    "        paths = []\n",
    "        texts = []\n",
    "        \n",
    "        with open(os.path.join(root_dir, path), 'r') as fr:\n",
    "            for line in tqdm(fr.readlines()):\n",
    "                line_stripped = line.strip()\n",
    "                \n",
    "                cur_path, index = line_stripped.split(' ')\n",
    "                \n",
    "                cur_path = os.path.join(root_dir, cur_path[2:])\n",
    "                index = int(index)\n",
    "                \n",
    "                paths.append(cur_path)\n",
    "                texts.append(mapping[index])\n",
    "                \n",
    "        self.paths = paths\n",
    "        self.texts = texts\n",
    "        self.mode = mode\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path = self.paths[index]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(path).convert('L')  # grey-scale\n",
    "        except IOError:\n",
    "            print('Corrupted image for %d' % index)\n",
    "            return self[index + 1]\n",
    "        \n",
    "        image = image.resize((self.img_width, self.img_height), resample=Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = image.reshape((1, self.img_height, self.img_width))\n",
    "        '''\n",
    "        img_min = np.min(image)\n",
    "        img_max = np.max(image)\n",
    "        image = (image - img_min) / (img_max - img_min)\n",
    "        '''\n",
    "        image = (image / 127.5) - 1.0\n",
    "        image = torch.FloatTensor(image)\n",
    "        \n",
    "        if self.texts:\n",
    "            text = self.texts[index]\n",
    "            target = [self.CHAR2LABEL[c] for c in text]\n",
    "            target_length = [len(target)]\n",
    "\n",
    "            target = torch.LongTensor(target)\n",
    "            target_length = torch.LongTensor(target_length)\n",
    "            \n",
    "            return image, target, target_length\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "def ocr_dataset_collate_fn(batch):\n",
    "    images, targets, target_lengths = zip(*batch)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.cat(targets, 0)\n",
    "    target_lengths = torch.cat(target_lengths, 0)\n",
    "    \n",
    "    return images, targets, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctc_decoder.py\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp  # log(p1 + p2) = logsumexp([log_p1, log_p2])\n",
    "\n",
    "NINF = -1 * float('inf')\n",
    "DEFAULT_EMISSION_THRESHOLD = 0.01\n",
    "\n",
    "\n",
    "def _reconstruct(labels, blank=0):\n",
    "    new_labels = []\n",
    "    # merge same labels\n",
    "    previous = None\n",
    "    for l in labels:\n",
    "        if l != previous:\n",
    "            new_labels.append(l)\n",
    "            previous = l\n",
    "    # delete blank\n",
    "    new_labels = [l for l in new_labels if l != blank]\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def greedy_decode(emission_log_prob, blank=0, **kwargs):\n",
    "    labels = np.argmax(emission_log_prob, axis=-1)\n",
    "    labels = _reconstruct(labels, blank=blank)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def beam_search_decode(emission_log_prob, blank=0, **kwargs):\n",
    "    beam_size = kwargs['beam_size']\n",
    "    emission_threshold = kwargs.get('emission_threshold', np.log(DEFAULT_EMISSION_THRESHOLD))\n",
    "\n",
    "    length, class_count = emission_log_prob.shape\n",
    "\n",
    "    beams = [([], 0)]  # (prefix, accumulated_log_prob)\n",
    "    for t in range(length):\n",
    "        new_beams = []\n",
    "        for prefix, accumulated_log_prob in beams:\n",
    "            for c in range(class_count):\n",
    "                log_prob = emission_log_prob[t, c]\n",
    "                if log_prob < emission_threshold:\n",
    "                    continue\n",
    "                new_prefix = prefix + [c]\n",
    "                # log(p1 * p2) = log_p1 + log_p2\n",
    "                new_accu_log_prob = accumulated_log_prob + log_prob\n",
    "                new_beams.append((new_prefix, new_accu_log_prob))\n",
    "\n",
    "        # sorted by accumulated_log_prob\n",
    "        new_beams.sort(key=lambda x: x[1], reverse=True)\n",
    "        beams = new_beams[:beam_size]\n",
    "\n",
    "    # sum up beams to produce labels\n",
    "    total_accu_log_prob = {}\n",
    "    for prefix, accu_log_prob in beams:\n",
    "        labels = tuple(_reconstruct(prefix))\n",
    "        # log(p1 + p2) = logsumexp([log_p1, log_p2])\n",
    "        total_accu_log_prob[labels] = \\\n",
    "            logsumexp([accu_log_prob, total_accu_log_prob.get(labels, NINF)])\n",
    "\n",
    "    labels_beams = [(list(labels), accu_log_prob)\n",
    "                    for labels, accu_log_prob in total_accu_log_prob.items()]\n",
    "    labels_beams.sort(key=lambda x: x[1], reverse=True)\n",
    "    labels = labels_beams[0][0]\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def prefix_beam_decode(emission_log_prob, blank=0, **kwargs):\n",
    "    beam_size = kwargs['beam_size']\n",
    "    emission_threshold = kwargs.get('emission_threshold', np.log(DEFAULT_EMISSION_THRESHOLD))\n",
    "\n",
    "    length, class_count = emission_log_prob.shape\n",
    "\n",
    "    beams = [(tuple(), (0, NINF))]  # (prefix, (blank_log_prob, non_blank_log_prob))\n",
    "    # initial of beams: (empty_str, (log(1.0), log(0.0)))\n",
    "\n",
    "    for t in range(length):\n",
    "        new_beams_dict = defaultdict(lambda: (NINF, NINF))  # log(0.0) = NINF\n",
    "\n",
    "        for prefix, (lp_b, lp_nb) in beams:\n",
    "            for c in range(class_count):\n",
    "                log_prob = emission_log_prob[t, c]\n",
    "                if log_prob < emission_threshold:\n",
    "                    continue\n",
    "\n",
    "                end_t = prefix[-1] if prefix else None\n",
    "\n",
    "                # if new_prefix == prefix\n",
    "                new_lp_b, new_lp_nb = new_beams_dict[prefix]\n",
    "\n",
    "                if c == blank:\n",
    "                    new_beams_dict[prefix] = (\n",
    "                        logsumexp([new_lp_b, lp_b + log_prob, lp_nb + log_prob]),\n",
    "                        new_lp_nb\n",
    "                    )\n",
    "                    continue\n",
    "                if c == end_t:\n",
    "                    new_beams_dict[prefix] = (\n",
    "                        new_lp_b,\n",
    "                        logsumexp([new_lp_nb, lp_nb + log_prob])\n",
    "                    )\n",
    "\n",
    "                # if new_prefix == prefix + (c,)\n",
    "                new_prefix = prefix + (c,)\n",
    "                new_lp_b, new_lp_nb = new_beams_dict[new_prefix]\n",
    "\n",
    "                if c != end_t:\n",
    "                    new_beams_dict[new_prefix] = (\n",
    "                        new_lp_b,\n",
    "                        logsumexp([new_lp_nb, lp_b + log_prob, lp_nb + log_prob])\n",
    "                    )\n",
    "                else:\n",
    "                    new_beams_dict[new_prefix] = (\n",
    "                        new_lp_b,\n",
    "                        logsumexp([new_lp_nb, lp_b + log_prob])\n",
    "                    )\n",
    "\n",
    "        # sorted by log(blank_prob + non_blank_prob)\n",
    "        beams = sorted(new_beams_dict.items(), key=lambda x: logsumexp(x[1]), reverse=True)\n",
    "        beams = beams[:beam_size]\n",
    "\n",
    "    labels = list(beams[0][0])\n",
    "    return labels\n",
    "\n",
    "\n",
    "def ctc_decode(log_probs, label2char=None, blank=0, method='beam_search', beam_size=10):\n",
    "    emission_log_probs = np.transpose(log_probs.cpu().numpy(), (1, 0, 2))\n",
    "    # size of emission_log_probs: (batch, length, class)\n",
    "\n",
    "    decoders = {\n",
    "        'greedy': greedy_decode,\n",
    "        'beam_search': beam_search_decode,\n",
    "        'prefix_beam_search': prefix_beam_decode,\n",
    "    }\n",
    "    decoder = decoders[method]\n",
    "\n",
    "    decoded_list = []\n",
    "    for emission_log_prob in emission_log_probs:\n",
    "        decoded = decoder(emission_log_prob, blank=blank, beam_size=beam_size)\n",
    "        if label2char:\n",
    "            decoded = [label2char[l] for l in decoded]\n",
    "        decoded_list.append(decoded)\n",
    "    return decoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate.py\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CTCLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from dataset import OCR_Dataset, ocr_dataset_collate_fn\n",
    "#from model import CRNN\n",
    "#from ctc_decoder import ctc_decode\n",
    "#from config import evaluate_config as config\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "def evaluate(crnn, dataloader, criterion,\n",
    "             max_iter=None, decode_method='beam_search', beam_size=10):\n",
    "    crnn.eval()\n",
    "\n",
    "    tot_count = 0\n",
    "    tot_loss = 0\n",
    "    tot_correct = 0\n",
    "    wrong_cases = []\n",
    "\n",
    "    pbar_total = max_iter if max_iter else len(dataloader)\n",
    "    pbar = tqdm(total=pbar_total, desc=\"Evaluate\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            if max_iter and i >= max_iter:\n",
    "                break\n",
    "            device = 'cuda' if next(crnn.parameters()).is_cuda else 'cpu'\n",
    "\n",
    "            images, targets, target_lengths = [d.to(device) for d in data]\n",
    "\n",
    "            logits = crnn(images)\n",
    "            log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "\n",
    "            batch_size = images.size(0)\n",
    "            input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "\n",
    "            loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "            preds = ctc_decode(log_probs, method=decode_method, beam_size=beam_size)\n",
    "            reals = targets.cpu().numpy().tolist()\n",
    "            target_lengths = target_lengths.cpu().numpy().tolist()\n",
    "\n",
    "            tot_count += batch_size\n",
    "            tot_loss += loss.item()\n",
    "            target_length_counter = 0\n",
    "            for pred, target_length in zip(preds, target_lengths):\n",
    "                real = reals[target_length_counter:target_length_counter + target_length]\n",
    "                target_length_counter += target_length\n",
    "                if pred == real:\n",
    "                    tot_correct += 1\n",
    "                else:\n",
    "                    wrong_cases.append((real, pred))\n",
    "\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    evaluation = {\n",
    "        'loss': tot_loss / tot_count,\n",
    "        'acc': tot_correct / tot_count,\n",
    "        'wrong_cases': wrong_cases\n",
    "    }\n",
    "    return evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    eval_batch_size = evaluate_config['eval_batch_size']\n",
    "    cpu_workers = evaluate_config['cpu_workers']\n",
    "    reload_checkpoint = evaluate_config['reload_checkpoint']\n",
    "\n",
    "    img_height = common_config['img_height']\n",
    "    img_width = common_config['img_width']\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "\n",
    "    test_dataset = OCR_Dataset(root_dir=evaluate_config['data_dir'], mode='test',\n",
    "                                   img_height=img_height, img_width=img_width)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cpu_workers,\n",
    "        collate_fn=ocr_dataset_collate_fn)\n",
    "\n",
    "    num_class = len(OCR_Dataset.LABEL2CHAR) + 1\n",
    "    crnn = CRNN(1, img_height, img_width, num_class,\n",
    "                map_to_seq_hidden=evaluate_config['map_to_seq_hidden'],\n",
    "                rnn_hidden=evaluate_config['rnn_hidden'],\n",
    "                use_leaky_relu=evaluate_config['use_leaky_relu'])\n",
    "    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "    crnn.to(device)\n",
    "\n",
    "    criterion = CTCLoss(reduction='sum')\n",
    "    criterion.to(device)\n",
    "\n",
    "    evaluation = evaluate(crnn, test_loader, criterion,\n",
    "                          decode_method=evaluate_config['decode_method'],\n",
    "                          beam_size=evaluate_config['beam_size'])\n",
    "    print('test_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88172/88172 [00:00<00:00, 658019.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa\n",
      "Running on GPU!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 32255.69it/s]\n",
      "100%|██████████| 88172/88172 [00:00<00:00, 419855.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 90905.83it/s]\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9/32 [00:03<00:08,  2.58it/s]\n",
      "Evaluate:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch_loss[ 10 ]:  30.772218704223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 9/32 [00:36<01:34,  4.11s/it]3.89s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3d501ec57efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-3d501ec57efb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalid_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                 evaluation = evaluate(crnn, valid_loader, criterion,\n\u001b[0m\u001b[0;32m    105\u001b[0m                                       \u001b[0mdecode_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'decode_method'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                       beam_size=eval_config['beam_size'])\n",
      "\u001b[1;32m<ipython-input-14-c96f114f256d>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(crnn, dataloader, criterion, max_iter, decode_method, beam_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctc_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mreals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mtarget_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-10ecd0e3c9cd>\u001b[0m in \u001b[0;36mctc_decode\u001b[1;34m(log_probs, label2char, blank, method, beam_size)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mdecoded_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0memission_log_prob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0memission_log_probs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memission_log_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabel2char\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel2char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-10ecd0e3c9cd>\u001b[0m in \u001b[0;36mbeam_search_decode\u001b[1;34m(emission_log_prob, blank, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mlog_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memission_log_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0memission_threshold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0mnew_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# log(p1 * p2) = log_p1 + log_p2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train.py\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "#from config import train_config as config\n",
    "#from dataset import OCR_Dataset, ocr_dataset_collate_fn\n",
    "#from model import CRNN\n",
    "#from evaluate import evaluate\n",
    "\n",
    "def train_batch(crnn, data, optimizer, criterion, device):\n",
    "    crnn.train()\n",
    "    images, labels, label_lengths = [d.to(device) for d in data]\n",
    "    \n",
    "    logits = crnn(images)\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "    \n",
    "    batch_size = images.size(0)\n",
    "    input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "    label_lengths = torch.flatten(label_lengths)\n",
    "    \n",
    "    loss = criterion(log_probs, labels, input_lengths, label_lengths)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def main():\n",
    "    print(\"Sa\")\n",
    "    epochs = train_config['epochs']\n",
    "    train_batch_size = train_config['train_batch_size']\n",
    "    eval_batch_size = train_config['eval_batch_size']\n",
    "    lr = train_config['lr']\n",
    "    show_interval = train_config['show_interval']\n",
    "    valid_interval = train_config['valid_interval']\n",
    "    save_interval = train_config['save_interval']\n",
    "    cpu_workers = train_config['cpu_workers']\n",
    "    reload_checkpoint = train_config['reload_checkpoint']\n",
    "    valid_max_iter = train_config['valid_max_iter']\n",
    "\n",
    "    img_width = common_config['img_width']\n",
    "    img_height = common_config['img_height']\n",
    "    data_dir = common_config['data_dir']\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(\"Running on GPU!\")\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"Running on CPU!\")\n",
    "        \n",
    "    train_dataset = OCR_Dataset(root_dir=data_dir, mode='train', \n",
    "                                     img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    valid_dataset = OCR_Dataset(root_dir=data_dir, mode='val', \n",
    "                                     img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=ocr_dataset_collate_fn)\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=eval_batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=ocr_dataset_collate_fn)\n",
    "\n",
    "    num_class = len(OCR_Dataset.LABEL2CHAR) + 1\n",
    "    crnn = CRNN(1, img_height, img_width, num_class,\n",
    "                map_to_seq_hidden= common_config['map_to_seq_hidden'],\n",
    "                rnn_hidden= common_config['rnn_hidden'],\n",
    "                use_leaky_relu= common_config['use_leaky_relu'])\n",
    "    if reload_checkpoint:\n",
    "        crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "    crnn.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(crnn.parameters(), lr=lr)\n",
    "    criterion = CTCLoss(reduction='sum')\n",
    "    criterion.to(device)\n",
    "    \n",
    "    i = 1\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'epoch: {epoch}')\n",
    "        tot_train_loss = 0.\n",
    "        tot_train_count = 0\n",
    "        for train_data in tqdm(train_loader):\n",
    "            \n",
    "            loss = train_batch(crnn, train_data, optimizer, criterion, device)\n",
    "            train_size = train_data[0].size(0)\n",
    "\n",
    "            tot_train_loss += loss\n",
    "            tot_train_count += train_size\n",
    "                \n",
    "        save_model_path = os.path.join(train_config['checkpoints_dir'],\n",
    "                                        f'{prefix}_{epoch:06}_loss{loss}.pt')\n",
    "        torch.save(crnn.state_dict(), save_model_path)\n",
    "        print('save model at ', save_model_path)\n",
    "        \n",
    "        evaluation = evaluate(crnn, valid_loader, criterion,\n",
    "                            decode_method=eval_config['decode_method'],\n",
    "                            beam_size=eval_config['beam_size'])\n",
    "        \n",
    "        print('valid_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n",
    "        print('epoch ', str(epoch), ': train_loss: ', tot_train_loss / tot_train_count)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict.py\n",
    "from docopt import docopt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import common_config as config\n",
    "from dataset import OCR_Dataset, ocr_dataset_collate_fn\n",
    "from model import CRNN\n",
    "from ctc_decoder import ctc_decode\n",
    "\n",
    "\n",
    "def predict(crnn, dataloader, label2char, decode_method, beam_size):\n",
    "    crnn.eval()\n",
    "    pbar = tqdm(total=len(dataloader), desc=\"Predict\")\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            device = 'cuda' if next(crnn.parameters()).is_cuda else 'cpu'\n",
    "\n",
    "            images = data.to(device)\n",
    "\n",
    "            logits = crnn(images)\n",
    "            log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "\n",
    "            preds = ctc_decode(log_probs, method=decode_method, beam_size=beam_size,\n",
    "                               label2char=label2char)\n",
    "            all_preds += preds\n",
    "\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    return all_preds\n",
    "\n",
    "\n",
    "def show_result(paths, preds):\n",
    "    print('\\n===== result =====')\n",
    "    for path, pred in zip(paths, preds):\n",
    "        text = ''.join(pred)\n",
    "        print(f'{path} > {text}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    arguments = docopt(__doc__)\n",
    "\n",
    "    images = arguments['IMAGE']\n",
    "    reload_checkpoint = arguments['-m']\n",
    "    batch_size = int(arguments['-s'])\n",
    "    decode_method = arguments['-d']\n",
    "    beam_size = int(arguments['-b'])\n",
    "\n",
    "    img_height = config['img_height']\n",
    "    img_width = config['img_width']\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: {device}')\n",
    "    \n",
    "    #todo: jotform dataset\n",
    "    predict_dataset = Synth90kDataset(paths=images,\n",
    "                                      img_height=img_height, img_width=img_width)\n",
    "\n",
    "    predict_loader = DataLoader(\n",
    "        dataset=predict_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "    num_class = len(Synth90kDataset.LABEL2CHAR) + 1\n",
    "    crnn = CRNN(1, img_height, img_width, num_class,\n",
    "                map_to_seq_hidden=config['map_to_seq_hidden'],\n",
    "                rnn_hidden=config['rnn_hidden'],\n",
    "                leaky_relu=config['leaky_relu'])\n",
    "    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "    crnn.to(device)\n",
    "\n",
    "    preds = predict(crnn, predict_loader, Synth90kDataset.LABEL2CHAR,\n",
    "                    decode_method=decode_method,\n",
    "                    beam_size=beam_size)\n",
    "\n",
    "    show_result(images, preds)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88172/88172 [00:00<00:00, 722735.56it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 142857.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OCR_Dataset(root_dir=train_config['data_dir'], mode='train', img_height=32, img_width=100)   \n",
    "\n",
    "train_loader = DataLoader( dataset=train_dataset, batch_size=10, shuffle=True, collate_fn=ocr_dataset_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "dataloader_iterator = iter(train_loader)\n",
    "\n",
    "'''\n",
    "for i in range(iterations):\n",
    "    print(i)\n",
    "    try:\n",
    "        X, Y = next(dataloader_iterator)\n",
    "    except:\n",
    "        dataloader_iterator = iter(train_loader)\n",
    "        X, Y = next(dataloader_iterator)\n",
    "    do_backprop(X, Y)\n",
    "'''\n",
    "\n",
    "len(next(dataloader_iterator))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
